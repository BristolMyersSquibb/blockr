[
  {
    "objectID": "getting-started.html",
    "href": "getting-started.html",
    "title": "Getting Started",
    "section": "",
    "text": "Install:\npak::pak(\"BristolMyersSquibb/blockr\")\nRun:\nblockr::run_app()\nThe blockr interface will open in your web browser. That’s it!\n\n\n\n\n\n\nNoteWhat does this do?\n\n\n\n\npak::pak() installs blockr and all five core packages (blockr.core, blockr.dplyr, blockr.ggplot, blockr.ui, blockr.io)\nblockr::run_app() launches the visual interface in your browser\nYou don’t need to know R programming—just copy and paste these commands",
    "crumbs": [
      "Home",
      "Getting Started",
      "Installation"
    ]
  },
  {
    "objectID": "getting-started.html#quick-start",
    "href": "getting-started.html#quick-start",
    "title": "Getting Started",
    "section": "",
    "text": "Install:\npak::pak(\"BristolMyersSquibb/blockr\")\nRun:\nblockr::run_app()\nThe blockr interface will open in your web browser. That’s it!\n\n\n\n\n\n\nNoteWhat does this do?\n\n\n\n\npak::pak() installs blockr and all five core packages (blockr.core, blockr.dplyr, blockr.ggplot, blockr.ui, blockr.io)\nblockr::run_app() launches the visual interface in your browser\nYou don’t need to know R programming—just copy and paste these commands",
    "crumbs": [
      "Home",
      "Getting Started",
      "Installation"
    ]
  },
  {
    "objectID": "getting-started.html#your-first-workflow",
    "href": "getting-started.html#your-first-workflow",
    "title": "Getting Started",
    "section": "Your First Workflow",
    "text": "Your First Workflow\nOnce you’ve launched blockr with blockr::run_app(), you’ll see the visual interface in your browser. Let’s create a simple data workflow using blocks.\n\nStep 1: Add a Data Source Block\n\nClick “Add Block” in the interface\nSelect “Read Block” from the I/O category\nChoose “Upload” mode\nUpload a CSV file from your computer\n\n\n\nStep 3: Add a Filter Block\n\nClick “Add Block” again\nSelect “Filter Block” from the Data Wrangling category\nConnect it to your Read Block\nUse the dropdown menus to set filter conditions\n\n\n\nStep 4: Add a Visualization Block\n\nAdd a “Plot Block” from the Visualization category\nSelect the type of plot you want (bar chart, scatter plot, etc.)\nChoose which columns to use for X and Y axes\nCustomize colors and labels\n\n\n\nStep 5: Export Your Results\n\nAdd an “Export Block”\nChoose your output format (PNG, PDF, Excel, etc.)\nClick “Export” to save your results\n\n\n\n\n\n\n\nTipWorking with blockr\n\n\n\nRemember, blockr is entirely visual—you don’t need to write any code once the interface is running. All configuration happens through dropdown menus, checkboxes, and input fields.",
    "crumbs": [
      "Home",
      "Getting Started",
      "Installation"
    ]
  },
  {
    "objectID": "getting-started.html#example-workflows",
    "href": "getting-started.html#example-workflows",
    "title": "Getting Started",
    "section": "Example Workflows",
    "text": "Example Workflows\n\nData Wrangling Example\nSee the Data Wrangling Showcase for detailed examples of:\n\nFiltering rows based on conditions\nSelecting specific columns\nCreating new calculated columns\nGrouping and summarizing data\nArranging rows in order\n\n\n\nFile I/O Example\nThe File I/O Showcase demonstrates:\n\nReading different file formats (CSV, Excel, etc.)\nLoading data from URLs\nHandling multiple files at once\nExporting results in various formats",
    "crumbs": [
      "Home",
      "Getting Started",
      "Installation"
    ]
  },
  {
    "objectID": "getting-started.html#next-steps",
    "href": "getting-started.html#next-steps",
    "title": "Getting Started",
    "section": "Next Steps",
    "text": "Next Steps\n\nExplore the Showcase: Browse the Data Wrangling and File I/O showcases to see all available blocks\nBuild Your Own: Start with your own data and experiment with different blocks\nGet Help: If you run into issues, open an issue on GitHub",
    "crumbs": [
      "Home",
      "Getting Started",
      "Installation"
    ]
  },
  {
    "objectID": "getting-started.html#learning-resources",
    "href": "getting-started.html#learning-resources",
    "title": "Getting Started",
    "section": "Learning Resources",
    "text": "Learning Resources\nEach showcase page includes screenshots and descriptions of how blocks work. Since blockr is visual and interactive, the best way to learn is by trying it yourself!\n\n\n\n\n\n\nTipTip for New Users\n\n\n\nStart with simple workflows (1-3 blocks) to get comfortable with the interface. As you become more familiar, you can build more complex multi-step pipelines.",
    "crumbs": [
      "Home",
      "Getting Started",
      "Installation"
    ]
  },
  {
    "objectID": "showcase/dplyr.html",
    "href": "showcase/dplyr.html",
    "title": "Data Wrangling Blocks",
    "section": "",
    "text": "blockr.dplyr provides interactive blocks for data wrangling. Each block offers a user interface for a specific data transformation task. Blocks can be connected together to create data transformation pipelines.",
    "crumbs": [
      "Home",
      "Block Showcase",
      "Data Wrangling Blocks"
    ]
  },
  {
    "objectID": "showcase/dplyr.html#introduction",
    "href": "showcase/dplyr.html#introduction",
    "title": "Data Wrangling Blocks",
    "section": "",
    "text": "blockr.dplyr provides interactive blocks for data wrangling. Each block offers a user interface for a specific data transformation task. Blocks can be connected together to create data transformation pipelines.",
    "crumbs": [
      "Home",
      "Block Showcase",
      "Data Wrangling Blocks"
    ]
  },
  {
    "objectID": "showcase/dplyr.html#select-block",
    "href": "showcase/dplyr.html#select-block",
    "title": "Data Wrangling Blocks",
    "section": "Select Block",
    "text": "Select Block\nThe select block chooses which columns to keep in your dataset.\nUse the column selector to pick the columns you want. You can select multiple columns and reorder them by dragging. The order of selection determines the column order in the output.\nThe block includes a “distinct” option. When enabled, duplicate rows are removed from the result, keeping only unique combinations of the selected columns.\n\n\n\n\n\nSelect block interface",
    "crumbs": [
      "Home",
      "Block Showcase",
      "Data Wrangling Blocks"
    ]
  },
  {
    "objectID": "showcase/dplyr.html#expression-filter-block",
    "href": "showcase/dplyr.html#expression-filter-block",
    "title": "Data Wrangling Blocks",
    "section": "Expression Filter Block",
    "text": "Expression Filter Block\nThe expression filter block keeps only rows that meet specific conditions. Enter logical expressions using column names and comparison operators. This block is designed for users who want to write filter conditions as expressions.\nSupported operators include &gt;, &lt;, ==, !=, &gt;=, &lt;= for comparisons, and %in% for checking membership in a set of values. Combine multiple conditions using & (AND) to require all conditions to be true, or | (OR) to require at least one condition to be true. The expression editor provides syntax highlighting and validates your expressions. Examples: mpg &gt; 20, cyl == 4 | cyl == 6, hp &gt; 100 & wt &lt; 3.\nIf you prefer to filter by selecting values from dropdowns rather than writing expressions, use the value filter block instead. The value filter block is particularly useful for categorical data where you want to pick specific values visually.\n\n\n\n\n\nFilter block interface",
    "crumbs": [
      "Home",
      "Block Showcase",
      "Data Wrangling Blocks"
    ]
  },
  {
    "objectID": "showcase/dplyr.html#value-filter-block",
    "href": "showcase/dplyr.html#value-filter-block",
    "title": "Data Wrangling Blocks",
    "section": "Value Filter Block",
    "text": "Value Filter Block\nThe value filter block filters rows by selecting values from dropdown lists. This provides a point-and-click interface that does not require writing expressions. Use this block when you want to visually select which values to include or exclude, especially for categorical columns.\nFor each filter condition, select a column from the dropdown. The interface displays all unique values in that column. Select one or more values to filter by. Choose between “include” mode (keep only rows with selected values) or “exclude” mode (remove rows with selected values). This is particularly useful when you want to see what values exist in a column before deciding which to filter.\nAdd multiple conditions using the “+” button. Each condition can be combined with the previous one using AND (all conditions must be true) or OR (at least one condition must be true) logic. The “preserve order” option maintains the order of selected values in the output.\nFor more complex filter conditions using comparisons or calculations, use the expression filter block instead. The expression filter block allows you to write expressions like mpg &gt; 20 or hp / wt &gt; 50 which cannot be expressed through value selection.\n\n\n\n\n\nValue filter block interface",
    "crumbs": [
      "Home",
      "Block Showcase",
      "Data Wrangling Blocks"
    ]
  },
  {
    "objectID": "showcase/dplyr.html#arrange-block",
    "href": "showcase/dplyr.html#arrange-block",
    "title": "Data Wrangling Blocks",
    "section": "Arrange Block",
    "text": "Arrange Block\nThe arrange block sorts rows by column values. Select one or more columns to sort by, with each column having its own ascending or descending control.\nWhen sorting by multiple columns, the order matters. The first column is the primary sort key. Rows with the same value in the first column are then sorted by the second column, and so on. Use the drag handles to reorder the sort columns.\nAdd columns using the “+” button and remove them using the “-” button. Toggle between ascending and descending order for each column independently.\n\n\n\n\n\nArrange block interface",
    "crumbs": [
      "Home",
      "Block Showcase",
      "Data Wrangling Blocks"
    ]
  },
  {
    "objectID": "showcase/dplyr.html#slice-block",
    "href": "showcase/dplyr.html#slice-block",
    "title": "Data Wrangling Blocks",
    "section": "Slice Block",
    "text": "Slice Block\nThe slice block selects specific rows based on different criteria. Choose from six slice types: head (first rows), tail (last rows), min (rows with smallest values), max (rows with largest values), sample (random selection), or custom (specific positions).\nFor head and tail types, specify the number of rows using n (count) or prop (proportion between 0 and 1). For min and max types, select an order_by column and enable with_ties if you want to include all rows with tied values. For sample type, optionally select a weight_by column for weighted sampling and enable replace for sampling with replacement.\nThe custom type accepts a rows expression like “1:5” or “c(1, 3, 5, 10)”. All slice types support grouping via the by parameter, which performs the slice operation within each group separately.\n\n\n\n\n\nSlice block interface",
    "crumbs": [
      "Home",
      "Block Showcase",
      "Data Wrangling Blocks"
    ]
  },
  {
    "objectID": "showcase/dplyr.html#mutate-block",
    "href": "showcase/dplyr.html#mutate-block",
    "title": "Data Wrangling Blocks",
    "section": "Mutate Block",
    "text": "Mutate Block\nThe mutate block creates new columns or modifies existing ones. Add multiple expressions, each creating or updating a column. Each expression consists of a column name and an expression that calculates its value.\nUse mathematical operators (+, -, *, /, ^) and functions (sqrt(), log(), round(), etc.) in your expressions. Reference existing columns by name. You can also use conditional logic with ifelse() or dplyr::case_when().\nExpression order matters: later expressions can reference columns created by earlier expressions in the same mutate block. The by parameter allows grouping, making column references operate within each group. Add expressions with the “+” button and remove them with the “-” button.\n\n\n\n\n\nMutate block interface",
    "crumbs": [
      "Home",
      "Block Showcase",
      "Data Wrangling Blocks"
    ]
  },
  {
    "objectID": "showcase/dplyr.html#rename-block",
    "href": "showcase/dplyr.html#rename-block",
    "title": "Data Wrangling Blocks",
    "section": "Rename Block",
    "text": "Rename Block\nThe rename block changes column names. Each rename operation maps a new name to an existing column. The interface shows the mapping as “new_name ← old_name” with a visual arrow indicator.\nSelect the existing column from a dropdown to ensure valid column names. Type the new name in the text field. Add multiple renames using the “+” button to rename several columns at once. Remove a rename operation with the “-” button.\nThe block validates that you don’t rename the same column twice and ensures column names don’t conflict with existing names.\n\n\n\n\n\nRename block interface",
    "crumbs": [
      "Home",
      "Block Showcase",
      "Data Wrangling Blocks"
    ]
  },
  {
    "objectID": "showcase/dplyr.html#summarize-block",
    "href": "showcase/dplyr.html#summarize-block",
    "title": "Data Wrangling Blocks",
    "section": "Summarize Block",
    "text": "Summarize Block\nThe summarize block calculates summary statistics. Add multiple summary expressions, each creating a new column in the output. Each expression consists of a column name and an aggregation expression.\nCommon aggregation functions include mean(), sum(), min(), max(), n() (count rows), n_distinct() (count unique values), median(), and sd(). Use the by parameter to group data before summarizing. When grouping is enabled, statistics are calculated separately for each group.\nThe unpack option controls how functions that return data frames are handled. When enabled, data frame results are unpacked into separate columns. This is useful with helpers like across() which can apply functions to multiple columns at once. For example, across(c(hp, wt), mean) with unpacking creates separate columns for each mean.\nAdd expressions with the “+” button. The interface validates expressions and shows errors if the aggregation is invalid.\n\n\n\n\n\nSummarize block interface",
    "crumbs": [
      "Home",
      "Block Showcase",
      "Data Wrangling Blocks"
    ]
  },
  {
    "objectID": "showcase/dplyr.html#join-block",
    "href": "showcase/dplyr.html#join-block",
    "title": "Data Wrangling Blocks",
    "section": "Join Block",
    "text": "Join Block\nThe join block combines two datasets based on matching values in specified columns. Select from six join types that determine which rows are kept in the result.\nJoin types: left_join keeps all rows from the left dataset and matching rows from the right; right_join keeps all rows from the right dataset and matching rows from the left; inner_join keeps only rows that match in both datasets; full_join keeps all rows from both datasets; semi_join filters the left dataset to rows that have a match in the right; anti_join filters the left dataset to rows that do not have a match in the right.\nThe join key interface supports both same-name joins (when columns have identical names) and different-name joins (when the matching columns have different names in each dataset). Add multiple join keys to match on multiple columns simultaneously. For different-name joins, specify which column from the left dataset matches which column from the right dataset.\n\n\n\n\n\nJoin block interface",
    "crumbs": [
      "Home",
      "Block Showcase",
      "Data Wrangling Blocks"
    ]
  },
  {
    "objectID": "showcase/dplyr.html#bind-rows-block",
    "href": "showcase/dplyr.html#bind-rows-block",
    "title": "Data Wrangling Blocks",
    "section": "Bind Rows Block",
    "text": "Bind Rows Block\nThe bind rows block stacks datasets vertically by matching column names. Rows from each input dataset are combined into a single output dataset.\nColumns are matched by name. If datasets have different columns, the result includes all columns from all datasets. Missing columns are filled with NA values. The order of columns in the output follows the order they appear across all input datasets.\nThe id_name option adds an identifier column that tracks which source dataset each row came from. This is useful when combining data from multiple sources and you need to maintain provenance. Enable this option and specify a column name to store the source identifier.\n\n\n\n\n\nBind rows block interface",
    "crumbs": [
      "Home",
      "Block Showcase",
      "Data Wrangling Blocks"
    ]
  },
  {
    "objectID": "showcase/dplyr.html#bind-columns-block",
    "href": "showcase/dplyr.html#bind-columns-block",
    "title": "Data Wrangling Blocks",
    "section": "Bind Columns Block",
    "text": "Bind Columns Block\nThe bind columns block combines datasets side-by-side horizontally. Columns from each input dataset are placed next to each other in the output.\nAll input datasets must have exactly the same number of rows. The rows are combined by position: the first row from each dataset forms the first row of the output, the second rows form the second row of the output, and so on.\nIf datasets have columns with the same name, the suffix option controls how to handle the duplicates. Specify suffixes to add to duplicate column names from each dataset. For example, suffixes c(\"_x\", \"_y\") would rename duplicate column “id” to “id_x” and “id_y”.\n\n\n\n\n\nBind columns block interface",
    "crumbs": [
      "Home",
      "Block Showcase",
      "Data Wrangling Blocks"
    ]
  },
  {
    "objectID": "showcase/dplyr.html#pivot-longer-block",
    "href": "showcase/dplyr.html#pivot-longer-block",
    "title": "Data Wrangling Blocks",
    "section": "Pivot Longer Block",
    "text": "Pivot Longer Block\nThe pivot longer block reshapes data from wide to long format using tidyr::pivot_longer(). Use this when column names represent values of a variable rather than variables themselves.\nSelect which columns to pivot. These columns are transformed into two new columns: one containing the original column names (names_to parameter, default “name”) and another containing the values (values_to parameter, default “value”). Unselected columns remain as identifiers.\nThe names_prefix option removes common prefixes from column names. The values_drop_na option removes rows where the value is NA. This is useful for reshaping time series data, survey responses, or preparing data for visualization.\n\n\n\n\n\nPivot longer block interface",
    "crumbs": [
      "Home",
      "Block Showcase",
      "Data Wrangling Blocks"
    ]
  },
  {
    "objectID": "showcase/dplyr.html#pivot-wider-block",
    "href": "showcase/dplyr.html#pivot-wider-block",
    "title": "Data Wrangling Blocks",
    "section": "Pivot Wider Block",
    "text": "Pivot Wider Block\nThe pivot wider block reshapes data from long to wide format using tidyr::pivot_wider(). This is the inverse of pivot longer, creating a summary table where row-column combinations become cells.\nSelect which column contains values for new column names (names_from) and which column contains cell values (values_from). The id_cols parameter specifies which columns identify each row. If empty, all columns not in names_from or values_from are used as identifiers.\nThe names_prefix option adds a prefix to new column names. The values_fill parameter provides a value for missing combinations (e.g., “0” or leave as NA). This is useful for creating crosstabs, pivot tables, or comparing values across categories.\n\n\n\n\n\nPivot wider block interface",
    "crumbs": [
      "Home",
      "Block Showcase",
      "Data Wrangling Blocks"
    ]
  },
  {
    "objectID": "showcase/dplyr.html#building-data-pipelines",
    "href": "showcase/dplyr.html#building-data-pipelines",
    "title": "Data Wrangling Blocks",
    "section": "Building Data Pipelines",
    "text": "Building Data Pipelines\nBlocks work together in pipelines. The output from one block becomes the input to the next. Each block shows a preview of the data at that stage.",
    "crumbs": [
      "Home",
      "Block Showcase",
      "Data Wrangling Blocks"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to blockr",
    "section": "",
    "text": "blockr is a block-based framework for data manipulation and visualization that lets you create powerful data workflows through a visual, point-and-click interface—no coding required.\n\n\n\n\n\n\nNoteFor Non-Coders\n\n\n\nIf you’re new to R or don’t know how to code, you’re in the right place! blockr is designed for you. Check out our Getting Started guide and Block Showcase to see what you can do.",
    "crumbs": [
      "Home",
      "Getting Started",
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#build-data-workflows-without-coding",
    "href": "index.html#build-data-workflows-without-coding",
    "title": "Welcome to blockr",
    "section": "",
    "text": "blockr is a block-based framework for data manipulation and visualization that lets you create powerful data workflows through a visual, point-and-click interface—no coding required.\n\n\n\n\n\n\nNoteFor Non-Coders\n\n\n\nIf you’re new to R or don’t know how to code, you’re in the right place! blockr is designed for you. Check out our Getting Started guide and Block Showcase to see what you can do.",
    "crumbs": [
      "Home",
      "Getting Started",
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#what-is-blockr",
    "href": "index.html#what-is-blockr",
    "title": "Welcome to blockr",
    "section": "What is blockr?",
    "text": "What is blockr?\nblockr is a unified meta-package that brings together five core packages:\n\nblockr.core - The foundation framework\nblockr.dplyr - Data wrangling blocks (filter, select, summarize, etc.)\nblockr.ggplot - Visualization blocks for creating plots\nblockr.ui - User interface components\nblockr.io - File input/output blocks\n\nTogether, these packages provide everything you need to:\n\n📊 Load data from files (CSV, Excel, and more)\n🔧 Transform and filter data visually\n📈 Create beautiful visualizations\n💾 Export results to files or reports",
    "crumbs": [
      "Home",
      "Getting Started",
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#how-it-works",
    "href": "index.html#how-it-works",
    "title": "Welcome to blockr",
    "section": "How it works",
    "text": "How it works\nInstead of writing code, you work with blocks:\n\nAdd blocks to your workspace by clicking\nConnect blocks together to create a data pipeline\nConfigure blocks using dropdowns, checkboxes, and input fields\nSee results in real-time as you build\n\nEach block performs a specific task (like filtering data or creating a plot), and blocks can be chained together to create complex workflows.",
    "crumbs": [
      "Home",
      "Getting Started",
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#quick-example",
    "href": "index.html#quick-example",
    "title": "Welcome to blockr",
    "section": "Quick Example",
    "text": "Quick Example\nHere’s what a typical blockr workflow looks like:\n[Read CSV] → [Filter Rows] → [Select Columns] → [Create Plot] → [Export]\nEach step is represented by a visual block with an intuitive interface. No code needed!",
    "crumbs": [
      "Home",
      "Getting Started",
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#explore-the-showcase",
    "href": "index.html#explore-the-showcase",
    "title": "Welcome to blockr",
    "section": "Explore the Showcase",
    "text": "Explore the Showcase\nSee what you can build with blockr:\n\nData Wrangling Blocks - Filter, select, transform, and summarize data\nFile I/O Blocks - Read and write files in multiple formats",
    "crumbs": [
      "Home",
      "Getting Started",
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#get-started-in-2-steps",
    "href": "index.html#get-started-in-2-steps",
    "title": "Welcome to blockr",
    "section": "Get Started in 2 Steps",
    "text": "Get Started in 2 Steps\nGetting blockr up and running is incredibly simple. If you have R installed, you can start using blockr in just two commands:\nStep 1: Install blockr\npak::pak(\"BristolMyersSquibb/blockr\")\nStep 2: Launch blockr\nblockr::run_app()\nThat’s it! The blockr interface will open in your browser, and you can start building workflows immediately.\n\n\n\n\n\n\nTipNew to R?\n\n\n\nEven if you’re not familiar with R, these two commands are all you need. Just copy and paste them into the R console. See the Getting Started guide for more details.",
    "crumbs": [
      "Home",
      "Getting Started",
      "Introduction"
    ]
  },
  {
    "objectID": "index.html#core-packages",
    "href": "index.html#core-packages",
    "title": "Welcome to blockr",
    "section": "Core Packages",
    "text": "Core Packages\nblockr is built on five specialized packages that work together:\n\nblockr.core - Framework and architecture\nblockr.dplyr - Data manipulation blocks\nblockr.ggplot - Plotting and visualization\nblockr.ui - User interface components\nblockr.io - File reading and writing\n\nInstalling blockr automatically installs all five packages, giving you the complete toolkit.",
    "crumbs": [
      "Home",
      "Getting Started",
      "Introduction"
    ]
  },
  {
    "objectID": "showcase/io.html",
    "href": "showcase/io.html",
    "title": "File I/O Blocks",
    "section": "",
    "text": "blockr.io provides unified file I/O blocks for reading and writing data in blockr pipelines. The read block handles loading data from multiple sources and formats with a smart, adaptive interface. The write block enables exporting data to various file formats, with support for browser downloads or filesystem output. Together, these blocks make it easy to build complete data workflows from input to output.",
    "crumbs": [
      "Home",
      "Block Showcase",
      "File I/O Blocks"
    ]
  },
  {
    "objectID": "showcase/io.html#introduction",
    "href": "showcase/io.html#introduction",
    "title": "File I/O Blocks",
    "section": "",
    "text": "blockr.io provides unified file I/O blocks for reading and writing data in blockr pipelines. The read block handles loading data from multiple sources and formats with a smart, adaptive interface. The write block enables exporting data to various file formats, with support for browser downloads or filesystem output. Together, these blocks make it easy to build complete data workflows from input to output.",
    "crumbs": [
      "Home",
      "Block Showcase",
      "File I/O Blocks"
    ]
  },
  {
    "objectID": "showcase/io.html#read-block",
    "href": "showcase/io.html#read-block",
    "title": "File I/O Blocks",
    "section": "Read Block",
    "text": "Read Block\nThe read block is a versatile data loading block that automatically adapts its interface based on the file type you’re working with. It combines three different file source modes (upload, browse, URL) with format-specific options for CSV, Excel, and other file types.\n\nThree Ways to Load Data\nUpload Mode: Drag and drop files or click to browse from your computer. Uploaded files are stored persistently, so they remain available across sessions. This is perfect for interactive data analysis where you want to upload a dataset once and keep working with it.\nBrowse Mode: Navigate your file system using an interactive file browser. Select files from configured folder paths. The block reads directly from the original file location without copying.\nURL Mode: Download data directly from a web URL. Simply paste a URL pointing to a CSV, Excel, or other supported file format. The data is downloaded fresh when the session starts.\n\n\nSmart Interface\nThe block detects your file type and shows relevant options:\nCSV/TSV files display options for delimiter (comma, semicolon, tab), quote character, encoding, row skipping, and whether the first row contains column names. This gives you full control over how delimited text files are parsed.\nExcel files show dropdown menus for sheet selection, cell range specification (like “A1:C100”), row skipping, and column name options. You can target specific sheets and ranges within your Excel workbooks.\nOther formats (Parquet, Feather, SPSS, Stata, SAS, JSON, XML, etc.) are handled automatically with minimal configuration. The block uses the appropriate reader based on file extension.\n\n\nWorking with Multiple Files\nWhen you select multiple files, the block provides combination strategies:\n\nAuto: Automatically stacks files vertically if they have the same columns, otherwise uses just the first file\nRow bind: Stack files vertically (requires files to have the same columns)\nColumn bind: Place files side-by-side (requires files to have the same number of rows)\nFirst only: Use only the first file, ignore the others\n\nThis makes it easy to load and combine related datasets in one step.\n\n\n\n\n\nRead block interface showing CSV options",
    "crumbs": [
      "Home",
      "Block Showcase",
      "File I/O Blocks"
    ]
  },
  {
    "objectID": "showcase/io.html#supported-file-formats",
    "href": "showcase/io.html#supported-file-formats",
    "title": "File I/O Blocks",
    "section": "Supported File Formats",
    "text": "Supported File Formats\nThe block supports a wide range of file formats:\nText formats: CSV, TSV, TXT, fixed-width files\nSpreadsheets: Excel (.xlsx, .xls), OpenDocument Spreadsheet (.ods)\nStatistical software: SPSS (.sav), Stata (.dta), SAS (.sas7bdat, .xpt)\nColumnar formats: Parquet, Feather, Arrow IPC\nWeb formats: JSON, XML, HTML\nR formats: RDS, RData\nDatabase formats: DBF, SQLite",
    "crumbs": [
      "Home",
      "Block Showcase",
      "File I/O Blocks"
    ]
  },
  {
    "objectID": "showcase/io.html#write-block",
    "href": "showcase/io.html#write-block",
    "title": "File I/O Blocks",
    "section": "Write Block",
    "text": "Write Block\nThe write block is a versatile data export block that accepts one or more dataframe inputs and outputs files in various formats. It provides flexible options for file naming, output location, and format-specific parameters.\n\nTwo Output Modes\nDownload Mode: The block triggers a browser download, saving the file to your downloads folder. This is the recommended mode for beginners and for exporting analysis results. Files are generated on-demand when you click the download button.\nBrowse Mode: Write files directly to the server filesystem. Use the directory browser to select where files should be saved. Files are written immediately when upstream data changes, making this ideal for automated pipelines.\n\n\nFilename Behavior\nFixed filename: Specify a filename (without extension) to create reproducible output. The block always writes to the same path, overwriting the file when upstream data changes. Perfect for automated workflows where you want consistent file paths.\nAuto-timestamped: Leave the filename empty to generate unique timestamped files (e.g., data_20250127_143022.csv). This preserves history and prevents accidental overwrites, making it the safe default behavior.\n\n\nMultiple Input Handling\nThe write block accepts multiple dataframe inputs, similar to how you might combine datasets. The output format depends on the file type:\nExcel format: Multiple inputs become sheets in a single Excel workbook. Sheet names are derived from input names (e.g., “sales_data”, “inventory”).\nCSV/Arrow formats: Multiple inputs are bundled into a ZIP archive. Each dataframe is saved as a separate file using the input names.\nSingle input: Outputs a single file in the specified format.\n\n\nSupported Output Formats\n\nCSV: Comma-separated values with configurable delimiter, quotes, and NA handling\nExcel: .xlsx workbooks with support for multiple sheets\nParquet: Efficient columnar storage format\nFeather: Fast binary format for data frames\n\nFormat-specific options (like CSV delimiter or quote character) can be configured through the args parameter.\n\n\n\n\n\nWrite block interface showing download mode",
    "crumbs": [
      "Home",
      "Block Showcase",
      "File I/O Blocks"
    ]
  },
  {
    "objectID": "showcase/io.html#building-complete-pipelines",
    "href": "showcase/io.html#building-complete-pipelines",
    "title": "File I/O Blocks",
    "section": "Building Complete Pipelines",
    "text": "Building Complete Pipelines\nThe read and write blocks work seamlessly with other blockr blocks to create end-to-end data workflows. Load data with the read block, transform it with processing blocks, visualize results, and export with the write block - all without writing code.\nFor example, you could build a pipeline that: 1. Loads sales data from a CSV file (read block) 2. Filters to show only high-revenue transactions (filter block) 3. Aggregates by product category (summarize block) 4. Creates a visualization (plot block) 5. Exports the processed data to Excel (write block)\nJust connect the blocks together to create powerful, reproducible data workflows!",
    "crumbs": [
      "Home",
      "Block Showcase",
      "File I/O Blocks"
    ]
  }
]